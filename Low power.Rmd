---
title: "Epilepsy Surgery Outcomes Power Review"
author: "Adam S Dickey"
date: "5/18/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

##libraries
library(readxl)
library(Exact) #Exact power calculation
library(tidyverse) #Needed for pipe, other stuff

```
### Load raw data

I will load the data from the Excel spreadsheet and show the first 6 rows.
```{r data}

samplesize <- read_excel("Dickey Appendix S1.xlsx")
head(samplesize)
numStudies <-nrow(samplesize)
minmax <-range(samplesize$nTot) 
```
Data was exacted from `r numStudies` studies.
The median sample size is `r median(samplesize$nTot)`, ranging from `r minmax[1]` to `r minmax[2]` subjects.

### Effect size
```{r}
percPos=204/305 #from Cardinal 2019, 204 of 305 MRI positive were seizure-free
percNeg=75/165 #from Cardinal 2019, 75 of 165 MRI negative were seizure-free
```
Based on the difference in MRI positive vs. MRI negative from Cardinale 2019, I will assume an effect size with seizure free rate of `r sprintf("%.1f%%",percPos*100)` in the positive group and `r sprintf("%.1f%%",percNeg*100)` in the negative group.

### Calculate power
I will compute the power for each study using the number of subjects in the positive group and number of subjects in the negative group, using the R package "Exact" and the Chi-square statistical test.

```{r}
powerVal <-rep(0,numStudies)
for (i in 1:numStudies) {
  temp <-power.exact.test(percPos,percNeg,samplesize$nA[i],samplesize$nB[i],method="pearson chisq")
  powerVal[i] <- temp$power
}
powerMedian <- median(powerVal)
moreThan50 = sum(powerVal>.5)
```
The median power is `r sprintf("%.1f%%",powerMedian*100)`.  Only `r moreThan50` of `r numStudies` studies have greater than 50% power.

### Select Power > 50%
``` {r}
samplesize2 <- cbind(samplesize,powerVal) #add power in

sorted <- sort(powerVal,decreasing=TRUE,index.return=TRUE) #sort from high power to low
t50 <-samplesize2[sorted$ix[1:moreThan50],]

#Compute seizure free % for positive and negative finding
#Use sprintf to keep one decimal place, add % sign
szFreePos <- sprintf("%.1f%%",t50$Apos/t50$nA*100)
szFreeNeg <- sprintf("%.1f%%",t50$Bpos/t50$nB*100)
powerNice <- sprintf("%.1f%%",t50$powerVal*100)

dataNice <- data.frame(t50$First_Author,t50$Year,t50$nTot,powerNice,t50$Exposure,t50$Outcome,szFreePos,szFreeNeg)
names(dataNice) <- c('Author', 'Year','N','Power','Finding','Outcome','%SR Pos', '%SR Neg')
knitr::kable(dataNice,align=c('l','l','c','c','l','l','c'))
```
**Table 1: Selected SEEG studies with greater than 50% statistical power.**  Power was calculated using a Chi-square test, assuming a difference in seizure freedom of `r sprintf("%.1f%%",percPos*100)` in group 1 and `r sprintf("%.1f%%",percNeg*100)` in group 2 (Odds Ratio 2.4).   Only `r moreThan50` of 69 studies had more than 50% power.  Abbreviations include sample size (N), % of patients with seizure reduction in the positive (SR+) or negative group (SR-), magnetic resonance imaging (MRI), low frequency stimulation (LFS), electrocorticography (ECOG), radiofrequency thermocoagulation (RF-TC)  .


## Power vs. Sample Size Plot

I will calculate the power for a range of sample sizes, assuming 2:1 allocation
```{r}
#Create data for plot
nMax <- 66
n1 <-c(1:nMax)
n2 <- 2*n1
nTot <- n1+n2

powerSampleSize <-rep(0,nMax)
for (i in 1:nMax) {
  temp <-power.exact.test(percPos,percNeg,n2[i],n1[i],method="pearson chisq")
  powerSampleSize[i] <- temp$power
}
```

Plotting code is hidden but included in the Rmd file
```{r, echo=FALSE}
#plot(nTot,powerSampleSize)
matplot(nTot,powerSampleSize*100,type = "l",xlab="Sample Size (N)",ylab="% Power",ylim=c(0,100),col='red')

ind80 <- which(powerSampleSize>.8)
ind <-ind80[1]
x <-c(nTot[ind],nTot[ind],0)
y <-c(0,powerSampleSize[ind],powerSampleSize[ind])
matplot(x,y*100,2,type = "l",add=TRUE)
points(x[2],y[2]*100)
text(160,90,'Well-powered study')


indMed <- which(powerSampleSize>powerMedian)
ind2 <- indMed[1]
x2 <-c(nTot[ind2],nTot[ind2],0)
y2 <-c(0,powerSampleSize[ind2],powerSampleSize[ind2])
matplot(x2,y2*100,3,type = "l",add=TRUE,col='blue')
points(x2[2],y2[2]*100,col='blue')
text(70,20,'Median SEEG study',col='blue')

```

**Figure 1: Power as a function of sample size.**  Assuming 2:1 allocation, a study would need `r nTot[ind]` subjects (`r n2[ind]` vs. `r n1[ind]`) to have 80% statistical power to detect a difference in seizure freedom of `r sprintf("%.1f%%",percPos*100)`in group 1 and `r sprintf("%.1f%%",percNeg*100)` in group 2.  However, the median SEEG study only has around `r sprintf("%.0f%%",powerMedian*100)` power to detect this difference.  For 2:1 allocation, this corresponds to a sample size of `r nTot[ind2]` (`r n2[ind2]` vs. `r n1[ind2]`).

Interestingly, the exact power calculation does not increase monotonically with increasing sample size. I think that is because the Chi-square test relies on a Gaussian approximation which doesn't apply for small sample sizes, and because for some values the percentages fall in between the discrete bins.